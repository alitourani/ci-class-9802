# -*- coding: utf-8 -*-
"""Bone Fracture Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E_jM5o5CzUnlOd3D7FBUqitharsRz1ag
"""

from google.colab import drive
drive.mount('/content/gdrive')

import os
os.environ['KAGGLE_CONFIG_DIR'] = "/content/gdrive/My Drive/Kaggle"
!pwd
!ls

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/My Drive/Kaggle
!pwd
!ls

!ls MURA-v1.1/valid

#!kaggle datasets download -d cjinny/mura-v11

#!unzip \*.zip
# !unzip \*.zip  && rm *.zip

###### IMPORTs ######
import cv2
import numpy as np
import tensorflow as tf
import tensorflow_hub as hub
import tensorflow_datasets as tfds
import os, glob, shutil
from tqdm.notebook import tqdm
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
from PIL import Image
import imgaug.augmenters as iaa
import uuid

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/My Drive/Kaggle/MURA-v1.1
!ls
!pwd

train_files = glob.glob("/content/gdrive/My Drive/Kaggle/MURA-v1.1/train/XR_HUMERUS/**/**/*.png")
valid_files = glob.glob("/content/gdrive/My Drive/Kaggle/MURA-v1.1/valid/XR_HUMERUS/**/**/*.png")
print(len(train_files))
print(len(valid_files))

# !rm -rf ./prep
# !ls ./prep

### Creat preprocessing floder for train ###
if os.path.isdir('./prep/train/negative/'):
  pass
else:
  os.makedirs('./prep/train/negative/')                                                                                                                          
  os.makedirs('./prep/train/positive/')
!ls
!pwd

####preprocssing data###
neg_c = 0
pos_c = 0
for file_name in tqdm(train_files, total=len(train_files)):
  label = file_name.split('/')[-2]
  if "negative" in label:
    shutil.copy(file_name, f'./prep/train/negative/image_{str(neg_c)}.png')
    neg_c += 1
  elif "positive" in label:
    shutil.copy(file_name, f'./prep/train/positive/image_{str(pos_c)}.png')
    pos_c += 1

### Creat Valid floder ###
if os.path.isdir('./prep/valid/negative/'):
  pass
else:
  os.makedirs('./prep/valid/negative/')
  os.makedirs('./prep/valid/positive/')

####preprocssing data####
neg_c = 0
pos_c = 0
for file_name in tqdm(valid_files, total=len(valid_files)):
  label = file_name.split('/')[-2]
  if "negative" in label:
    shutil.copy(file_name, f'./prep/valid/negative/image_{str(neg_c)}.png')
    neg_c += 1
  elif "positive" in label:
    shutil.copy(file_name, f'./prep/valid/positive/image_{str(pos_c)}.png')
    pos_c += 1

!pwd
!ls /content/gdrive/My\ Drive/Kaggle/MURA-v1.1/prep/train

train_dir = "/content/gdrive/My Drive/Kaggle/MURA-v1.1/prep/train/"
valid_dir = "/content/gdrive/My Drive/Kaggle/MURA-v1.1/prep/valid/"
train_pos = "/content/gdrive/My Drive/Kaggle/MURA-v1.1/prep/train/positive/"
train_neg = "/content/gdrive/My Drive/Kaggle/MURA-v1.1/prep/train/negative/"
val_pos = "/content/gdrive/My Drive/Kaggle/MURA-v1.1/prep/valid/positive/"
val_neg = "/content/gdrive/My Drive/Kaggle/MURA-v1.1/prep/valid/negative/"
total_train, total_val = (1272), (288)

print(f"train positive images: {len(os.listdir(train_pos))}")
print(f"train negative images: {len(os.listdir(train_neg))}")
print(f"valid positive images: {len(os.listdir(val_pos))}")
print(f"valid negative images: {len(os.listdir(val_neg))}")

IMG_SIZE = 150
batch_size = 16
epochs = 30

train_generator = ImageDataGenerator(rescale=1./255)
valid_generator = ImageDataGenerator(rescale=1./255)

train_data_gen = train_generator.flow_from_directory(
    batch_size=batch_size, directory=train_dir, shuffle=True,
    target_size=(IMG_SIZE, IMG_SIZE),class_mode = 'binary'
)

val_data_gen = valid_generator.flow_from_directory(
    batch_size=batch_size, directory=valid_dir, shuffle=True,
    target_size=(IMG_SIZE, IMG_SIZE),class_mode = 'binary'
)

module_url = 'https://tfhub.dev/google/imagenet/inception_v3/classification/4'

model = tf.keras.Sequential([
    hub.KerasLayer(module_url, 
                   input_shape=(IMG_SIZE, IMG_SIZE, 3), trainable=False),
    tf.keras.layers.Dropout(rate=0.3),
    tf.keras.layers.Dense(1, activation='sigmoid',
                          kernel_regularizer=tf.keras.regularizers.l2(0.0001))
])

model.summary()

model.compile(optimizer='adam',
              loss='binary_crossentropy', 
              metrics=['accuracy'])

history = model.fit_generator(
    train_data_gen,
    steps_per_epoch=total_train // batch_size,
    epochs=epochs,
    validation_data=val_data_gen,
    validation_steps=total_val // batch_size,

)

#saving model 
model.save("/content/gdrive/My Drive/Kaggle/result_Humerus.h5")

import json
his = history.history
with open("/content/gdrive/My Drive/Kaggle/history_Humerus.json", 'w') as file:
  json.dump(his, file)









